---
title: 'Learning Interpretable and Transferable Rope Manipulation Policies Using Depth Sensing and Dense Object Descriptors'
authors: 'Priya Sundaresan, Brijen Thananjeyan, Ashwin Balakrishna, Michael Laskey, Kevine Stone, Joseph E. Gonzalez, Ken Goldberg'
venue: 'IEEE International Conference on Robotics and Automation (ICRA)'
date: 2020-05-31
category: 'submitted'
pdf: '2020_ICRA_Rope.pdf'
teaser: '2020_ICRA_Rope.png'
permalink: /publication/2020-rope-icra
collection: publications
---

Abstract
-------
Robotic manipulation of deformable 1D objects such as ropes, cables, and threads is challenging due to the lack of analytic models and large configuration spaces. Furthermore, learning end-to-end manipulation policies directly from images and physical interaction requires significant time cost on a robot and can fail to generalize across tasks. We address these challenges using interpretable deep visual representations for rope extending recent work on dense object descriptors for robot manipulation. This facilitates the design of interpretable and transferable geometric policies built on top of the learned representations, decoupling visual reasoning and control. We present an approach that learns point-pair correspondences between rope configurations, which implicitly encodes geometric structure, entirely in simulation from synthetic depth images. We demonstrate that the learned representation can be used to manipulate a real rope into a variety of different arrangements either by learning from demonstrations or using intuitive geometric policies. In 50 trials of a knot-tying task with the ABB YuMi Robot, the system achieves 66% knot-tying success from unseen configurations. See https://tinyurl.com/rope- learning for supplementary material and videos.
